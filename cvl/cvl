#ifndef CVL_HPP
#define CVL_HPP

#include <memory>
#include <thread>
#include <chrono>
#include <functional>

#include <queue.hpp>
#include <pipeline.hpp>

#include <opencv2/core.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>

namespace cvl {

using TFrameCallback = std::function<void (const cv::Mat&)>;

struct camera {

    camera() {
        _pipelineConfig[IDX_MOCAP_ALGO] = 3;
        _pipelineConfig[IDX_SKIP_FRAMES] = 4;
        _pipelineConfig[IDX_PIPELINE_FLAGS] = 2;
        _pipelineConfig[IDX_PIPELINE_STAGES] = 0;
        _pipelineConfig[IDX_FACE_CONFIDENCE] = 5;
        _pipelineConfig[IDX_OBJECT_CONFIDENCE] = 5;
        _pipelineConfig[IDX_FACEREC_CONFIDENCE] = 60;
        _pipelineConfig[IDX_MOCAP_EXCLUDE_AREA] = 2500;
        _pipelineConfig[IDX_BOUNDINGBOX_THICKNESS] = 1;
        _pipelineConfig[IDX_BOUNDINGBOX_INCREMENT] = 0;
    }

    ~camera() {
        stop();
    }

    void start(TFrameCallback cbk) {
        stop();
        _process_thread = std::thread(&camera::process_frames, this);
        if (cbk) {
            _frame_cbk = cbk;
            _queue_thread = std::thread(&camera::queue_frames, this);
        } else {
            camera::queue_frames();
        }
    }

    void stop() {
        _stop = true;
        if (_queue_thread.joinable())
            _queue_thread.join();
        if (_process_thread.joinable())
            _process_thread.join();
        _stop = false;
    }

    std::string _name;
    std::string _source;
    double m_scalef = 1.0;
    int _waitKeyTimeout = 0;
    std::string _resultsFolder;
    int _pipelineConfig[16] = { 0 };

    private:

    bool _stop = false;
    cvl::queue<cv::Mat> q_in;
    cvl::queue<cv::Mat> q_out;
    TFrameCallback _frame_cbk;
    std::thread _queue_thread;
    std::thread _process_thread;

    void queue_frames(void) {
        cv::VideoCapture cap;
        cap.set(cv::CAP_PROP_HW_ACCELERATION, cv::VIDEO_ACCELERATION_ANY);
        if (_source.length() == 1 && isdigit(_source[0])) {
            cap.open(std::stoi(_source), cv::CAP_ANY);
        } else {
            cap.open(_source, cv::CAP_ANY);
        }
        if (!cap.isOpened()) {
            ERR << "queue_frames error: unable to open camera";
            _stop = true;
        }
        cv::Mat f_in;
        while (!_stop) {
            cap >> f_in;
            q_in.enqueue(f_in);
            auto f_out = q_out.dequeue();
            if (!f_out.empty()) {
                if (_frame_cbk) {
                    _frame_cbk(f_out);
                } else {
                    cv::imshow("live", f_out);
                }
            }
            if (_waitKeyTimeout > 0) {
                if (cv::waitKey(_waitKeyTimeout) >= 0) {
                    _stop = true;
                    break;
                }
            }
        }
        DBG << "queue_frames thread returning";
    }

    void process_frames() {
        cvl::pipeline pipeLine;
        while (!_stop) {
            auto frame = q_in.dequeue();
            if (frame.empty()) {
                std::this_thread::sleep_for(std::chrono::milliseconds(50));
                continue;
            }
            if (_pipelineConfig[IDX_PIPELINE_STAGES]) {
                pipeLine.execute(frame, _pipelineConfig, _resultsFolder);
            }
            q_out.enqueue(frame);
        }
        DBG << "process_frames thread returning";
    }
};

inline auto entry(std::vector<std::string> arguments) {
    std::string source = "0";
    if (arguments.size() > 1) {
        source = arguments[1];
    }
    auto cam = std::make_unique<cvl::camera>();
    cam->_source = source;
    cam->_pipelineConfig[IDX_PIPELINE_STAGES] = 16;
    cam->start(nullptr);
    getchar();
}

using SPCamera = std::shared_ptr<camera>;
using UPCamera = std::unique_ptr<camera>;

}

#endif