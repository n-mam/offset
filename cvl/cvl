#ifndef CVL_HPP
#define CVL_HPP

#include <memory>
#include <thread>
#include <chrono>
#include <functional>

#include <queue.hpp>
#include <pipeline.hpp>

#include <opencv2/core.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>

namespace cvl {

using namespace std::chrono;
using TFrameCallback = std::function<void (const cv::Mat&)>;

class camera
{
    public:

    camera()
    {
        iPipelineConfig[IDX_SKIP_FRAMES] = 4;
        iPipelineConfig[IDX_MOCAP_ALGO] = 3;
        iPipelineConfig[IDX_PIPELINE_STAGES] = 0;
        iPipelineConfig[IDX_FACE_CONFIDENCE] = 5;
        iPipelineConfig[IDX_OBJECT_CONFIDENCE] = 5;
        iPipelineConfig[IDX_FACEREC_CONFIDENCE] = 60;
        iPipelineConfig[IDX_MOCAP_EXCLUDE_AREA] = 2500;
        iPipelineConfig[IDX_BOUNDINGBOX_THICKNESS] = 2;
        iPipelineConfig[IDX_BOUNDINGBOX_INCREMENT] = 0;
    }

    ~camera()
    {
        stop();
    }

    void start(TFrameCallback cbk)
    {
        stop();

        _process_thread = std::thread(&camera::process_frames, this);

        if (cbk) {
            _frame_cbk = cbk;
            _queue_thread = std::thread(&camera::queue_frames, this);
        } else {
            camera::queue_frames();
        }
    }

    void stop()
    {
        _stop = true;
        if (_queue_thread.joinable())
            _queue_thread.join();
        if (_process_thread.joinable())
            _process_thread.join();
        _stop = false;
    }

    std::string iName;

    std::string iSource;

    int iWaitKeyTimeout = 18;

    std::string iResultsFolder;

    int iPipelineConfig[16] = { 0 };

    private:

    bool _stop = false;

    cvl::queue<cv::Mat> q_in;

    cvl::queue<cv::Mat> q_out;

    TFrameCallback _frame_cbk;

    std::thread _queue_thread;

    std::thread _process_thread;

    void queue_frames(void)
    {
        cv::VideoCapture cap;
        cap.set(cv::CAP_PROP_HW_ACCELERATION, cv::VIDEO_ACCELERATION_ANY);

        if (iSource.length() == 1 && isdigit(iSource[0]))
            cap.open(std::stoi(iSource), cv::CAP_ANY);
        else
            cap.open(iSource, cv::CAP_ANY);

        if (!cap.isOpened()) {
            ERR << "queue_frames, error: unable to open camera";
            _stop = true;
        }

        cv::Mat f_in;

        while (!_stop) {

            cap >> f_in;

            q_in.enqueue(f_in);

            auto f_out = q_out.dequeue();

            if (!f_out.empty()) {
                if (_frame_cbk) {
                    _frame_cbk(f_out);
                }  else {
                    cv::imshow("live", f_out);
                }
            }

            if (iWaitKeyTimeout >= 0) {
                if (cv::waitKey(iWaitKeyTimeout) >= 0) {
                    _stop = true;
                    break;
                }
            }
        }

        DBG << "queue_frames thread returning";
    }

    void process_frames()
    {
        cvl::pipeline pipeLine;

        while (!_stop) {

            auto frame = q_in.dequeue();

            if (frame.empty()) {
                std::this_thread::sleep_for(milliseconds(50));
                continue;
            }

            if (iPipelineConfig[IDX_PIPELINE_STAGES]) {
                pipeLine.execute(frame, iPipelineConfig, iResultsFolder);
            }

            q_out.enqueue(frame);
        }

        DBG << "process_frames thread returning";
    }
};

inline auto entry(std::vector<std::string> arguments)
{
    std::string source = "0";

    source = arguments[1];

    auto cam = std::make_unique<cvl::camera>();

    cam->iSource = source;

    cam->iPipelineConfig[IDX_PIPELINE_STAGES] = 16;

    cam->start(nullptr);

    getchar();
}

using SPCamera = std::shared_ptr<camera>;
using UPCamera = std::unique_ptr<camera>;

}

#endif