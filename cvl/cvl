#ifndef CVL_HPP
#define CVL_HPP

#include <memory>
#include <thread>
#include <chrono>
#include <functional>

#include <queue.hpp>
#include <pipeline.hpp>

#include <opencv2/core.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>

namespace cvl {

using TFrameCallback = std::function<void (const cv::Mat&)>;

struct camera {

    camera() {
        cc = std::make_shared<cvl::cam_config>();
        cc->_flags = 0;
        cc->_mocapAlgo = 3;
        cc->_skipFrames = 2;
        cc->_bbIncrement = 0;
        cc->_bbThickness = 1;
        cc->_faceConfidence = 5;
        cc->_stages = 0;
        cc->_objectConfidence = 5;
        cc->_facerecConfidence = 60;
        cc->_mocapExcludeArea = 2500;
    }

    ~camera() {
        stop();
    }

    void start(TFrameCallback cbk) {
        stop();
        _process_thread = std::thread(&camera::process_frames, this);
        if (cbk) {
            _frame_cbk = cbk;
            _queue_thread = std::thread(&camera::queue_frames, this);
        } else {
            camera::queue_frames();
        }
    }

    void stop() {
        _stop = true;
        if (_queue_thread.joinable())
            _queue_thread.join();
        if (_process_thread.joinable())
            _process_thread.join();
        _count = 0;
        _stop = false;
        q_in.clear();
        q_out.clear();
    }

    std::string _name;
    std::string _source;
    double m_scalef = 1.0;
    int _waitKeyTimeout = 0;
    std::string _resultsFolder;
    uint32_t _pipelineConfig[16] = { 0 };
    std::shared_ptr<cvl::cam_config> cc;

    private:

    bool _stop = false;
    uint32_t _count = 0;
    cvl::queue<cv::Mat> q_in;
    cvl::queue<cv::Mat> q_out;
    TFrameCallback _frame_cbk;
    std::thread _queue_thread;
    std::thread _process_thread;

    void queue_frames(void) {
        cv::VideoCapture cap;
        cap.set(cv::CAP_PROP_HW_ACCELERATION, cv::VIDEO_ACCELERATION_ANY);
        if (_source.length() == 1 && isdigit(_source[0])) {
            cap.open(std::stoi(_source), cv::CAP_ANY);
        } else {
            cap.open(_source, cv::CAP_ANY);
        }
        if (!cap.isOpened()) {
            ERR << "queue_frames error: unable to open camera";
            _stop = true;
        }
        cv::Mat f_in;
        while (!_stop) {
            _count++;
            cap >> f_in;
            if ((_count % cc->_skipFrames) == 0) {
                q_in.enqueue(f_in);
                auto f_out = q_out.dequeue();
                if (!f_out.empty()) {
                    if (_frame_cbk) {
                        _frame_cbk(f_out);
                    } else {
                        cv::imshow("live", f_out);
                    }
                }
                if (_waitKeyTimeout > 0) {
                    if (cv::waitKey(_waitKeyTimeout) >= 0) {
                        _stop = true;
                        break;
                    }
                }
            }
        }
        DBG << "queue_frames thread returning";
    }

    void process_frames() {
        cvl::pipeline pipeLine;
        while (!_stop) {
            auto frame = q_in.dequeue();
            if (frame.empty()) {
                std::this_thread::sleep_for(std::chrono::milliseconds(50));
                continue;
            }
            if (cc->_stages) {
                pipeLine.execute(frame, cc, _resultsFolder);
            }
            q_out.enqueue(frame);
        }
        DBG << "process_frames thread returning";
    }
};

inline auto entry(std::vector<std::string> arguments) {
    std::string source = "0";
    if (arguments.size() > 1) {
        source = arguments[1];
    }
    auto cam = std::make_unique<cvl::camera>();
    cam->_source = source;
    cam->cc->_stages = 16;
    cam->start(nullptr);
    getchar();
}

using SPCamera = std::shared_ptr<camera>;
using UPCamera = std::unique_ptr<camera>;
}

#endif